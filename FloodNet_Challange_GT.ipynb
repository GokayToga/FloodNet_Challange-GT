{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1155yzdnFv6vpssblRstk8hXRo4oe2KXQ",
      "authorship_tag": "ABX9TyPPazAN8yoZ5bq3Np7sxTt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GokayToga/FloodNet_Challange-GT/blob/main/FloodNet_Challange_GT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Do:\n",
        "\n",
        "*   resize the images to 713x713 ✅\n",
        "*   Augment the images with random shuffling, scal- ing, flipping, and random rotation ❓\n",
        "*  First Build basic U-net to experiment\n",
        "*  Then PSPNet, ENet, and DeepLabv3+ can be implemented and experimented on.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8UytJyo4Pyft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vOz81OFzaDTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdfadc5-13cc-4705-8f84-47c4d617bddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "o8JiYotYeutr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from collections import Counter\n",
        "\n",
        "from tensorflow.image import resize as tf_resize\n",
        "from tensorflow import io as tf_io\n",
        "from tensorflow import image as tf_image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "bn1rqjfLe6FV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Resizing and Augmentation"
      ],
      "metadata": {
        "id": "leLPRMOBQxe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE = (713,713) #shape of resized image\n",
        "drive_path = \"/content/drive/MyDrive/FloodNet-Supervised_v1.0\"\n",
        "local_path = \"/content/Augmented_Data\"\n",
        "\n",
        "def Augment_Resize(path, resize=RESIZE):\n",
        "  #used_path = os.path.join(drive_path, path) #path for diffent datasets\n",
        "  used_path = drive_path + path\n",
        "  save_format = os.path.splitext(used_path)[1].lower()\n",
        "\n",
        "  Aug_parameters = ImageDataGenerator(   #augmentation parameters\n",
        "      rescale=1./255,          # Scaling\n",
        "      horizontal_flip=True,    # Random horizontal flip\n",
        "      vertical_flip=True,      # Random vertical flip\n",
        "      rotation_range=45        # Random rotation in the range [-45, 45] degrees\n",
        "  )\n",
        "\n",
        "  if len(os.listdir(used_path)) > 1:\n",
        "\n",
        "    length = len(os.listdir(used_path))\n",
        "    #print( length )\n",
        "\n",
        "    for img_name in tqdm(os.listdir(used_path)):\n",
        "      img_path = used_path + img_name\n",
        "      # Read and resize the image\n",
        "      img = cv2.imread(img_path)\n",
        "\n",
        "      # Check if the image was read successfully\n",
        "      if img is not None:\n",
        "        img = cv2.resize(img, resize)\n",
        "\n",
        "        # Reshape to meet the requirements of ImageDataGenerator\n",
        "        img = img.reshape((1,) + img.shape)\n",
        "\n",
        "        # Generate augmented images\n",
        "        for batch in Aug_parameters.flow(img, batch_size=1, save_to_dir=local_path, save_prefix=img_name.split('.')[0], save_format=save_format):\n",
        "          break  # Stop after one augmented image (to avoid infinite loop)\n",
        "      else:\n",
        "        print(f\"Error: Unable to read image at {img_path}\")\n",
        "  else:\n",
        "    print(f\"{path}  images are already saved\")\n"
      ],
      "metadata": {
        "id": "apMuV-t0RVVJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data resizer :\n",
        "- (Because of the problems in augmentation we countinue with only resizing)"
      ],
      "metadata": {
        "id": "53tzC3cFge49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "RESIZE = (713,713) #shape of resized image\n",
        "drive_path = \"/content/drive/MyDrive/FloodNet-Supervised_v1.0\"\n",
        "local_path = \"/content/Augmented_Data\"\n",
        "\n",
        "def Augment_Resize2(path, resize=RESIZE):\n",
        "  #used_path = os.path.join(drive_path, path) #path for diffent datasets\n",
        "  used_path = drive_path + path\n",
        "  save_format = os.path.splitext(used_path)[1].lower()\n",
        "\n",
        "\n",
        "  if len(os.listdir(used_path)) > 1:\n",
        "\n",
        "    length = len(os.listdir(used_path))\n",
        "    #print( length )\n",
        "\n",
        "    for img_name in tqdm(os.listdir(used_path)):\n",
        "      img_path = used_path + \"/\" + img_name #os.path.join(used_path, img_name)\n",
        "      save_path = local_path + path + \"/\" + img_name\n",
        "      #print(f\"Attempting to read image at: {img_path}\")\n",
        "\n",
        "      try:\n",
        "          img = imageio.imread(img_path)\n",
        "      except Exception as e:\n",
        "          print(f\"Error: {e}\")\n",
        "          continue\n",
        "\n",
        "      # Check if the image was read successfully\n",
        "      if img is not None:\n",
        "\n",
        "        img = cv2.resize(img, resize)\n",
        "        imageio.imwrite(save_path, img)\n",
        "\n",
        "      else:\n",
        "        print(f\"Error: Unable to read image at {img_path}\")\n",
        "  else:\n",
        "    print(f\"{path}  images are already saved\")\n"
      ],
      "metadata": {
        "id": "mcijjIOdS3ep"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "Augment_Resize2(\"/test/test-label-img\")\n",
        "Augment_Resize2(\"/test/test-org-img\")\n",
        "\n",
        "#Train\n",
        "Augment_Resize2(\"/train/train-label-img\")\n",
        "Augment_Resize2(\"/train/train-org-img\")\n",
        "\n",
        "#Val\n",
        "Augment_Resize2(\"/val/val-label-img\")\n",
        "Augment_Resize2(\"/val/val-org-img\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QLXAdoiSYwdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model:"
      ],
      "metadata": {
        "id": "NWlA0wXNg4iE"
      }
    }
  ]
}