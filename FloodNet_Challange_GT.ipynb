{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1155yzdnFv6vpssblRstk8hXRo4oe2KXQ",
      "authorship_tag": "ABX9TyMgdCmVnP9Nl8R5oRfu0Dn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GokayToga/FloodNet_Challange-GT/blob/main/FloodNet_Challange_GT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Do:\n",
        "\n",
        "*   resize the images to 713x713\n",
        "*   Augment the images with random shuffling, scal- ing, flipping, and random rotation\n",
        "*  First Build basic U-net to experiment\n",
        "*  Then PSPNet, ENet, and DeepLabv3+ can be implemented and experimented on.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8UytJyo4Pyft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vOz81OFzaDTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8325f56-19be-425c-fbdb-ea01e40ad564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "o8JiYotYeutr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from collections import Counter\n",
        "\n",
        "from tensorflow.image import resize as tf_resize\n",
        "from tensorflow import io as tf_io\n",
        "from tensorflow import image as tf_image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "bn1rqjfLe6FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Resizing and Augmentation"
      ],
      "metadata": {
        "id": "leLPRMOBQxe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE(713,713) #shape of resized image\n",
        "drive_path = \"/content/drive/MyDrive/FloodNet-Supervised_v1.0\"\n",
        "local_path = \"/content/512_Images\"\n",
        "\n",
        "def Augment_Resize(path, resize=RESIZE):\n",
        "  used_path = os.path.join(temp_root, path) #path for diffent datasets\n",
        "  save_format = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "  Aug_parameters = ImageDataGenerator(   #augmentation parameters\n",
        "      rescale=1./255,          # Scaling\n",
        "      horizontal_flip=True,    # Random horizontal flip\n",
        "      vertical_flip=True,      # Random vertical flip\n",
        "      rotation_range=45        # Random rotation in the range [-45, 45] degrees\n",
        "  )\n",
        "\n",
        "  if len(os.listdir(used_path)) == 1:\n",
        "    print(f\"{path}  images are already saved\")\n",
        "  else:\n",
        "    length = len(os.listdir(used_path))\n",
        "\n",
        "    for img_name in tqdm(os.listdir(used_path)):\n",
        "      # Read and resize the image\n",
        "      img = cv2.imread(img_path)\n",
        "      img = cv2.resize(img, resize)\n",
        "\n",
        "      # Reshape to meet the requirements of ImageDataGenerator\n",
        "      img = img.reshape((1,) + img.shape)\n",
        "\n",
        "      # Generate augmented images\n",
        "      for batch in datagen.flow(img, batch_size=1, save_to_dir=used_path, save_prefix=img_name.split('.')[0], save_format=save_format):\n",
        "        break  # Stop after one augmented image (to avoid infinite loop)\n"
      ],
      "metadata": {
        "id": "apMuV-t0RVVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "Augment_Resize(\"/test/test-label-img\")\n",
        "Augment_Resize(\"/test/test-org-img\")\n",
        "\n",
        "#Train\n",
        "Augment_Resize(\"/train/train-label-img\")\n",
        "Augment_Resize(\"/train/train-org-img\")\n",
        "\n",
        "#Val\n",
        "Augment_Resize(\"/val/train-label-img\")\n",
        "Augment_Resize(\"/val/train-org-img\")\n"
      ],
      "metadata": {
        "id": "QLXAdoiSYwdB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}