{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1155yzdnFv6vpssblRstk8hXRo4oe2KXQ",
      "authorship_tag": "ABX9TyNL+3vUrCO9TDX0l/v3dvRp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GokayToga/FloodNet_Challange-GT/blob/main/FloodNet_Challange_GT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Do:\n",
        "\n",
        "*   resize the images to 713x713 ✅\n",
        "*   Augment the images with random shuffling, scaling, flipping, and random rotation ✅\n",
        "*  First Build basic U-net to experiment\n",
        "*  Then PSPNet, ENet, and DeepLabv3+ can be implemented and experimented on.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8UytJyo4Pyft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vOz81OFzaDTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad54efcd-b343-4af2-bbbf-80145937271d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "o8JiYotYeutr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from collections import Counter\n",
        "\n",
        "from tensorflow.image import resize as tf_resize\n",
        "from tensorflow import io as tf_io\n",
        "from tensorflow import image as tf_image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "bn1rqjfLe6FV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Resizing and Augmentation"
      ],
      "metadata": {
        "id": "leLPRMOBQxe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "struct = \"\"\"\n",
        "FloodNet Challenge @ EARTHVISION 2021 - Track 1\n",
        "|\n",
        "│   class_mapping.csv\n",
        "│\n",
        "└──>Train\n",
        "│   │\n",
        "│   └──>Labeled\n",
        "│   |\n",
        "|   |   |   |\n",
        "|   │   |   └──>image\n",
        "|   |   |   |\n",
        "|   │   |   └──>mask\n",
        "|   |   |\n",
        "│   |   └──>Non-Flooded\n",
        "|   |       |\n",
        "|   │       └──>image\n",
        "|   |       |\n",
        "|   │       └──>mask\n",
        "│   │\n",
        "│   └──>Unlabeled\n",
        "|       │\n",
        "│       └──>image\n",
        "|\n",
        "└──>Validation\n",
        "    │\n",
        "    └──>...\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "j7TwiVmDeEXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE = (713,713) #shape of resized image\n",
        "drive_path = \"/content/drive/MyDrive/FloodNet-Supervised_v1.0\"\n",
        "local_path = \"/content/Augmented_Data\"\n",
        "\n",
        "def Augment_Resize(path, resize=RESIZE):\n",
        "  #used_path = os.path.join(drive_path, path) #path for diffent datasets\n",
        "  used_path = drive_path + path\n",
        "  save_format = os.path.splitext(used_path)[1].lower()\n",
        "\n",
        "  Aug_parameters = ImageDataGenerator(   #augmentation parameters\n",
        "      rescale=1./255,          # Scaling\n",
        "      horizontal_flip=True,    # Random horizontal flip\n",
        "      vertical_flip=True,      # Random vertical flip\n",
        "      rotation_range=45        # Random rotation in the range [-45, 45] degrees\n",
        "  )\n",
        "\n",
        "  if len(os.listdir(used_path)) > 1:\n",
        "\n",
        "    length = len(os.listdir(used_path))\n",
        "    #print( length )\n",
        "\n",
        "    for img_name in tqdm(os.listdir(used_path)):\n",
        "      img_path = used_path + img_name\n",
        "      # Read and resize the image\n",
        "      img = cv2.imread(img_path)\n",
        "\n",
        "      # Check if the image was read successfully\n",
        "      if img is not None:\n",
        "        img = cv2.resize(img, resize)\n",
        "\n",
        "        # Reshape to meet the requirements of ImageDataGenerator\n",
        "        img = img.reshape((1,) + img.shape)\n",
        "\n",
        "        # Generate augmented images\n",
        "        for batch in Aug_parameters.flow(img, batch_size=1, save_to_dir=local_path, save_prefix=img_name.split('.')[0], save_format=save_format):\n",
        "          break  # Stop after one augmented image (to avoid infinite loop)\n",
        "      else:\n",
        "        print(f\"Error: Unable to read image at {img_path}\")\n",
        "  else:\n",
        "    print(f\"{path}  images are already saved\")\n"
      ],
      "metadata": {
        "id": "apMuV-t0RVVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data resizer :\n",
        "- (Because of the problems in augmentation we countinue with only resizing)"
      ],
      "metadata": {
        "id": "53tzC3cFge49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "RESIZE = (713,713) #shape of resized image\n",
        "drive_path = \"/content/drive/MyDrive/FloodNet-Supervised_v1.0\"\n",
        "local_path = \"/content/Augmented_Data\"\n",
        "\n",
        "def Augment_Resize2(path, resize=RESIZE):\n",
        "  #used_path = os.path.join(drive_path, path) #path for diffent datasets\n",
        "  used_path = drive_path + path\n",
        "  save_format = os.path.splitext(used_path)[1].lower()\n",
        "\n",
        "\n",
        "  if len(os.listdir(used_path)) > 1:\n",
        "\n",
        "    length = len(os.listdir(used_path))\n",
        "    #print( length )\n",
        "\n",
        "    for img_name in tqdm(os.listdir(used_path)):\n",
        "      img_path = used_path + \"/\" + img_name #os.path.join(used_path, img_name)\n",
        "      save_path = local_path + path + \"/\" + img_name\n",
        "      #print(f\"Attempting to read image at: {img_path}\")\n",
        "\n",
        "      try:\n",
        "          img = imageio.imread(img_path)\n",
        "      except Exception as e:\n",
        "          print(f\"Error: {e}\")\n",
        "          continue\n",
        "\n",
        "      # Check if the image was read successfully\n",
        "      if img is not None:\n",
        "\n",
        "        img = cv2.resize(img, resize)\n",
        "        imageio.imwrite(save_path, img)\n",
        "\n",
        "      else:\n",
        "        print(f\"Error: Unable to read image at {img_path}\")\n",
        "  else:\n",
        "    print(f\"{path}  images are already saved\")\n"
      ],
      "metadata": {
        "id": "mcijjIOdS3ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "Augment_Resize2(\"/test/test-label-img\")\n",
        "Augment_Resize2(\"/test/test-org-img\")\n",
        "\n",
        "#Train\n",
        "Augment_Resize2(\"/train/train-label-img\")\n",
        "Augment_Resize2(\"/train/train-org-img\")\n",
        "\n",
        "#Val\n",
        "Augment_Resize2(\"/val/val-label-img\")\n",
        "Augment_Resize2(\"/val/val-org-img\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QLXAdoiSYwdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38c5b70-8114-4c3a-f211-06466deb1237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/448 [00:00<?, ?it/s]<ipython-input-3-d434104c1896>:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  img = imageio.imread(img_path)\n",
            "100%|██████████| 448/448 [00:46<00:00,  9.62it/s]\n",
            "100%|██████████| 448/448 [02:36<00:00,  2.87it/s]\n",
            "100%|██████████| 1445/1445 [02:25<00:00,  9.95it/s]\n",
            "100%|██████████| 1445/1445 [09:49<00:00,  2.45it/s]\n",
            "100%|██████████| 450/450 [00:49<00:00,  9.02it/s]\n",
            "100%|██████████| 450/450 [02:45<00:00,  2.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Moving the data to Drive"
      ],
      "metadata": {
        "id": "_3tXkZ8FL2xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Augmented_Data /content/drive/MyDrive\n"
      ],
      "metadata": {
        "id": "HxSobXXyLyTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Downloading the data"
      ],
      "metadata": {
        "id": "A3buYfWEL8bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Augmented_Data')"
      ],
      "metadata": {
        "id": "RR20SM8cL_gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming and Augmenting Data"
      ],
      "metadata": {
        "id": "NWlA0wXNg4iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEGMENTS = {'Background':0,'Building-flooded':1,'Building-non-flooded':2,'Road-flooded':3,'Road-non-flooded':4,\n",
        "         'Water':5,'Tree':6,'Vehicle':7,'Pool':8,'Grass':9}\n",
        "DIMENSIONS = 713"
      ],
      "metadata": {
        "id": "tic7FyqWIiJC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Aug_parameters = ImageDataGenerator(   #augmentation parameters\n",
        "      rescale=1./255,          # Scaling\n",
        "      horizontal_flip=True,    # Random horizontal flip\n",
        "      vertical_flip=True,      # Random vertical flip\n",
        "      rotation_range=45        # Random rotation in the range [-45, 45] degrees\n",
        "  )"
      ],
      "metadata": {
        "id": "cIQSFpNcXiO2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SegDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x_paths, y_labels, batch_size, transform=None):\n",
        "        self.x_paths = x_paths\n",
        "        self.y_labels = y_labels\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_x_paths = self.x_paths[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "        batch_y_labels = self.y_labels[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = [cv2.imread(path) for path in batch_x_paths]\n",
        "        batch_labels = batch_y_labels\n",
        "\n",
        "        if self.transform:\n",
        "            batch_images = self.transform.flow(batch_images, batch_size=len(batch_images), shuffle=False)\n",
        "\n",
        "        batch_images = [cv2.resize(img, DIMENSIONS) / 255.0 for img in batch_images]\n",
        "\n",
        "        return tf.convert_to_tensor(batch_images, dtype=tf.float32), tf.convert_to_tensor(batch_labels, dtype=tf.int64)\n"
      ],
      "metadata": {
        "id": "KSF0oJPiZ3mn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data pathways or sm\n",
        "#path : /content/drive/MyDrive/Augmented_Data\n",
        "#specific path : /content/drive/MyDrive/Augmented_Data/test/test-label-img"
      ],
      "metadata": {
        "id": "ljwOhFUoWu7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "nqGQtnRUWwDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   First Configuration\n",
        "\n"
      ],
      "metadata": {
        "id": "p9mznUlehs7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Paths return empty check that!!\n",
        "\n",
        "def create_paths(base_path, dataset_type):\n",
        "    label = dataset_type + \"-label-img\"\n",
        "    labeled_path = os.path.join(base_path, dataset_type, label)\n",
        "\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "\n",
        "    for class_folder in os.listdir(labeled_path):\n",
        "        class_path = os.path.join(labeled_path, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for image_folder in os.listdir(os.path.join(class_path, 'image')):\n",
        "                image_paths += [os.path.join(base_path, dataset_type, class_folder, 'image', image_folder, filename) for filename in os.listdir(os.path.join(class_path, 'image', image_folder))]\n",
        "\n",
        "            for mask_folder in os.listdir(os.path.join(class_path, 'mask')):\n",
        "                mask_paths += [os.path.join(base_path, dataset_type, class_folder, 'mask', mask_folder, filename) for filename in os.listdir(os.path.join(class_path, 'mask', mask_folder))]\n",
        "\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Assuming your dataset is in the 'Dataset' directory\n",
        "base_dataset_path = '/content/drive/MyDrive/Augmented_Data'\n",
        "\n",
        "# Create paths for training data\n",
        "x_train_paths, y_train_paths = create_paths(base_dataset_path, 'train')\n",
        "# Create paths for test data\n",
        "x_test_paths, y_test_paths = create_paths(base_dataset_path, 'test')\n",
        "# Create paths for val data\n",
        "x_test_paths, y_test_paths = create_paths(base_dataset_path, 'val')\n",
        "\n",
        "# Print the first few paths for verification\n",
        "print(x_train_paths[:5])\n",
        "print(y_train_paths[:5])\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = SegDataset(x_train_paths, y_train_paths, batch_size=batch_size, transform = Aug_parameters)\n",
        "test_dataset = SegDataset(x_test_paths, y_test_paths, batch_size=batch_size, transform=None)  # No augmentation for the test set\n",
        "image_datasets = {'train_set': train_dataset, 'test_set': test_dataset}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vjU9Ay3W21Y",
        "outputId": "fcf28f3d-b165-4226-d8c5-dbcac4040172"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Training the model\n",
        "\n"
      ],
      "metadata": {
        "id": "qphS5pW_ldU7"
      }
    }
  ]
}